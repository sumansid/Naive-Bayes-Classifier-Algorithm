{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and Constants\n",
    "top_words_size = 4000\n",
    "\n",
    "word_spam_prob_file = 'prob-spam.txt'\n",
    "word_ham_prob_file = 'prob-ham.txt'\n",
    "word_all_prob_file ='prob-all.txt'\n",
    "\n",
    "test_words_matrix = 'test-words.txt'\n",
    "test_target_file = 'test-target.txt'\n",
    "test_email_csv='test-email-csv.txt'\n",
    "\n",
    "top_words = pd.read_csv('topwords.csv')\n",
    "# Prior (Guess) in Bayesian Statistics \n",
    "prob_spam = 0.3113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.49960417e-03 4.58874336e-03 6.42329261e-03 ... 4.26639362e-05\n",
      " 4.74043735e-06 9.48087471e-06]\n"
     ]
    }
   ],
   "source": [
    "# Load the Probabilities\n",
    "prob_word_spam = np.loadtxt(word_spam_prob_file, delimiter=' ')\n",
    "prob_word_ham = np.loadtxt(word_ham_prob_file, delimiter=' ')\n",
    "prob_word_all = np.loadtxt(word_all_prob_file, delimiter=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Email body function\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_email_body(email):\n",
    "    \"\"\"\n",
    "    email : user given email to filter\n",
    "    \n",
    "    returns : a list of tokenized, filtered words from the input given to the function\n",
    "    \"\"\"\n",
    "    filtered_words = []\n",
    "    words_in_email = word_tokenize(email)\n",
    "    for word in words_in_email: \n",
    "        if word.isalpha() and word not in stopwords.words('english'):\n",
    "            filtered_words.append(stemmer.stem(word.lower()))\n",
    "            \n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_email = \"Dear mom, I am out with my friends playing football. So, I will arrive home late. Please leave the door open.\"\n",
    "\n",
    "example_email_1 = \"Dear user, PLease click on the link below to get the prize the you have won\"\n",
    "example_3 = \"\"\"Hi Andrew,\n",
    "\n",
    "I plan on making a simpler form of naive Bayes classifier using conditional Bayes probability theorem that I learnt in my high school (Attached with this email). Following are some steps that I will be following : \n",
    "\n",
    "1. Gathering the Spam Assasin Corpus : https://spamassassin.apache.org/old/publiccorpus/\n",
    "2. Preprocessing the spam and non spam emails by removing any html tags present in the email, word stemming and removing punctuations.\n",
    "3. Putting all the email bodies in a pandas dataframe and tokenizing.\n",
    "4. Finding occurrences of words in both spam and nonspam emails. (I plan on using the top 4000 most occuring words)\n",
    "5. Finding the probability of occurrence of words in spam and nonspam emails (Conditional Probability).\n",
    "6. Implementing Bayes Theorem to the result found from above ie. 5. \n",
    "\n",
    "\n",
    "\n",
    "Throughout my final project, I will be referencing Andrew Ng videos and the statsoft's bayes classifier overview. I will be evaluating the effectiveness using the idea of false and true positives, negatives. \"\"\"\n",
    "\n",
    "email_body = \"Dear Suman, I am a little busy this morning and won't be in my office. Please meet me on monday during my office hours. I can help you with the final project and will also talk to you about your plan for winter. I will provide you with guidance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_email():\n",
    "    \"\"\"\n",
    "    Function that checks if a user given email is spam or not. \n",
    "    This function asks the user for email as input and checks whether it is spam or not.\n",
    "    \n",
    "    Return : Spam for spam detection and Non-Spam for non spam detection\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    email = str(input(\"Enter an email: \"))\n",
    "    email = clean_email_body(email)\n",
    "    \n",
    "    \n",
    "    # Empty df\n",
    "    column_names = list(range(0, top_words_size))\n",
    "    empty_df = pd.DataFrame(index=['User_Email'], columns=column_names)\n",
    "    empty_df.fillna(value=0, inplace=True)\n",
    "    # Populate the empty dataframe\n",
    "    for word in email:\n",
    "        if word in set(top_words.Top_Words):\n",
    "            \n",
    "            idx = top_words.Word_ID.loc[top_words.Top_Words == word].values[0]\n",
    "            \n",
    "            empty_df[idx] = empty_df[idx] + 1\n",
    "            \n",
    "    populated_df = empty_df\n",
    "    \n",
    "    populated_df.to_csv(test_email_csv)\n",
    "    # Get the probability of the whole email being spam and not spam\n",
    "    full_email_spam = populated_df.values.dot((np.log(prob_word_spam) - np.log(prob_word_all)))+ np.log(prob_spam)\n",
    "    full_email_ham = populated_df.values.dot((np.log(prob_word_ham) - np.log(prob_word_all))) + np.log(1-prob_spam)\n",
    "    # Check which probability is greater\n",
    "    result = full_email_spam[0] > full_email_ham[0]\n",
    "    \n",
    "    if result:\n",
    "\n",
    "        return \"Spam\"\n",
    "    else:\n",
    "        return \"Non-Spam\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter an email: Hi Andrew, Can you meet me during my office hour today?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Non-Spam'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_user_email()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word_ID        2692\n",
       "Top_Words    andrew\n",
       "Name: 2692, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words.iloc[2692]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
